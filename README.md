
# ğŸ“Œ IMAGE CLASSIFICATION USING CNN ON CIFAR-10

## ğŸ“ MÃ´n há»c: Nháº­p mÃ´n xá»­ lÃ½ áº£nh sá»‘  
**TrÆ°á»ng:** Äáº¡i há»c VÄƒn Lang  
**GVHD:** Tháº§y Äá»— Há»¯u QuÃ¢n, Tháº§y Nguyá»…n ThÃ¡i Anh  
**Sinh viÃªn thá»±c hiá»‡n:** LÃª ÄÃ¬nh QuÃ¢n â€“ 207CT40568  
**NhÃ³m:** 25  
**Lá»›p há»c pháº§n:** 243_71ITAI40803_01

---

## ğŸ“– Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y thá»±c hiá»‡n xÃ¢y dá»±ng má»™t há»‡ thá»‘ng **phÃ¢n loáº¡i áº£nh tá»± Ä‘á»™ng** sá»­ dá»¥ng máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN â€“ Convolutional Neural Network) vá»›i táº­p dá»¯ liá»‡u **CIFAR-10**. ÄÃ¢y lÃ  Ä‘á»“ Ã¡n mÃ´n há»c "Nháº­p mÃ´n xá»­ lÃ½ áº£nh sá»‘", káº¿t há»£p giá»¯a lÃ½ thuyáº¿t vÃ  thá»±c hÃ nh nháº±m giÃºp sinh viÃªn hiá»ƒu rÃµ hÆ¡n vá»:

- Tiá»n xá»­ lÃ½ áº£nh
- Thiáº¿t káº¿ kiáº¿n trÃºc CNN
- ÄÃ¡nh giÃ¡ vÃ  cáº£i thiá»‡n mÃ´ hÃ¬nh há»c sÃ¢u

---

## ğŸ§  Kiáº¿n thá»©c sá»­ dá»¥ng

- **Xá»­ lÃ½ áº£nh sá»‘**: chuáº©n hÃ³a, tÄƒng cÆ°á»ng dá»¯ liá»‡u, mÃ£ hÃ³a nhÃ£n
- **Máº¡ng CNN**: Conv2D, Pooling, Flatten, Dense, Dropout
- **Huáº¥n luyá»‡n mÃ´ hÃ¬nh**: optimizer Adam, loss `categorical_crossentropy`
- **ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh**: accuracy, trá»±c quan hÃ³a loss/accuracy theo epoch

---

## ğŸ› ï¸ CÃ´ng nghá»‡

- ğŸ”¤ **NgÃ´n ngá»¯**: Python 3.10  
- ğŸ“¦ **ThÆ° viá»‡n chÃ­nh**:
  - TensorFlow, Keras
  - NumPy, Matplotlib, scikit-learn  
- ğŸ§ª **Ná»n táº£ng cháº¡y mÃ´ hÃ¬nh**: Google Colab (há»— trá»£ GPU)

---

## ğŸ“‚ Cáº¥u trÃºc mÃ´ hÃ¬nh CNN

```python
cnn = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),

    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),

    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),

    layers.Flatten(),
    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')
])
```

---

## ğŸ§ª Káº¿t quáº£ thá»±c nghiá»‡m

- ğŸ¯ Äá»™ chÃ­nh xÃ¡c Ä‘áº¡t ~**80%** trÃªn táº­p kiá»ƒm tra sau 10 epoch
- ğŸ“‰ Loss giáº£m Ä‘á»u, accuracy tÄƒng á»•n Ä‘á»‹nh
- âœ… KhÃ´ng overfitting rÃµ rá»‡t
- ğŸ†š So vá»›i random baseline (10%), mÃ´ hÃ¬nh vÆ°á»£t trá»™i

---

## ğŸ“Š Dataset: CIFAR-10

- ğŸ“· 60.000 áº£nh mÃ u RGB (32x32)
- ğŸ§© 10 lá»›p: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck

---

## ğŸš€ HÆ°á»›ng phÃ¡t triá»ƒn

- NÃ¢ng cao mÃ´ hÃ¬nh vá»›i ResNet, VGG, hoáº·c Transfer Learning
- Ãp dá»¥ng ká»¹ thuáº­t tÄƒng cÆ°á»ng dá»¯ liá»‡u (Data Augmentation)
- Triá»ƒn khai giao diá»‡n cho ngÆ°á»i dÃ¹ng upload áº£nh vÃ  phÃ¢n loáº¡i
- So sÃ¡nh nhiá»u kiáº¿n trÃºc CNN khÃ¡c nhau

---

## ğŸ”— LiÃªn káº¿t

- ğŸ“ Notebook mÃ´ hÃ¬nh: [Doancuoiky.ipynb](https://github.com/Ldinhquan/-n-cu-i-k---Nh-p-m-n-x-l-nh-s-/blob/main/Doancuoiky.ipynb)

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

- CIFAR-10 Dataset: Krizhevsky & Hinton (2009)
- Keras Examples: [Image classification with modern convnets](https://keras.io/examples/vision/image_classification_from_scratch/)
- Kaggle CIFAR-10 CNN: https://www.kaggle.com/code/faressayah/cifar-10-images-classification-using-cnns-88
- Papers With Code: [Image Classification on CIFAR-10](https://paperswithcode.com/sota/image-classification-on-cifar-10)
